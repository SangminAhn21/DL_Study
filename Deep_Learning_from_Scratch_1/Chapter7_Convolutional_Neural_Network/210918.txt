AlexNet의 합성곱 계층의 학습 결과를 시각화한 결과
얇은 층에서는 에지, 블롭 등의 단순한 패턴에 반응하고, 
층이 깊어질 수록 텍스쳐, 사물의 일부 등 복잡한 정보에 반응한다. 

LeNet은 초기 단계의 CNN이다. CNN과의 차이점은, CNN은 ReLU를 활성화함수로 사용하는데 반해, 
LeNet은 sigmoid함수를 사용한다는 것이다. 또한, 맥스풀링이 아닌 서블샘플링을 사용하여 중간 데이터의 크기를 줄이낟. 

AlexNet은 ReLU를 사용한다. 또한, LRN(Local Response Normalization)이라는 국소적 정규화를 실시하고 드롭아웃을 사용한다. 
AlexNet과 LeNet은 네트워크 구성 측면에선 큰 차이가 없다.
성능 차이를 만들어내는 것은 빅데이터와 GPU이다. 